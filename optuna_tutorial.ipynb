{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Hyperparameter Optimization with Optuna\n",
    "\n",
    "Tutorial\n",
    "\n",
    "### Jefferson Fialho Coelho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.trial import TrialState\n",
    "from optuna.importance import MeanDecreaseImpurityImportanceEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definitions:\n",
    "* **Parameter**:\n",
    "> A model parameter is a configuration variable that is **internal to the model** and whose value can be **estimated from data.**\n",
    "  \n",
    "  * E.g.:\n",
    "    * The coefficients (or weights) of linear and logistic regression models.\n",
    "    * Weights and biases of a nn\n",
    "    * The cluster centroids in clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Definitions:\n",
    "  \n",
    "* **Hiperparameter**:\n",
    "> A model hyperparameter is a configuration that is **external to the model** and whose value **cannot be estimated from data.**\n",
    "   \n",
    "   * E.g.:\n",
    "     * Learning rate\n",
    "     * Dropout rate\n",
    "     * Early stop\n",
    "     * Neurons\n",
    "     * Layers\n",
    "     * alpha, beta, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter tuning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When we need to tune?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div>\n",
    "    <img src=\"img/just_runs.jpg\" style=\"width:600px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter tuning Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div>\n",
    "    <img src=\"img/headache.jpg\" style=\"width:375px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hyperparameter tuning Complexity\n",
    "\n",
    "* A **NP-Hard** problem\n",
    "* **High-dimensionality** problem\n",
    "  * X hyperparameters creates X dimension to describe a objetive function/best combination\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tuning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>Hyperparameter search space</h1></center>\n",
    "<br>\n",
    "A surface to be searched where:\n",
    "\n",
    "<li><b>each dimension represents a hyperparameter</b> and </li>\n",
    "<li><b>each point represents one model configuration</b> (hyperparameter set) </li>\n",
    "<br><br>\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/blinds.png\" style=\"width:500px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h1>Hand tuning by \"trial and error\"</h1></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/blinds720.gif\" style=\"margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## **Hand tuning** by \"trial and error\"\n",
    "\n",
    "* for hyperparameter_1:\n",
    "   * for hyperparameter_2:\n",
    "     * for hyperparameter_3:\n",
    "       * for hyperparameter_4:\n",
    "          * ...\n",
    "          \n",
    "* Computationally **expensive**\n",
    "* **Curse of dimensionality**\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/run.png\" style=\"width:300px; margin:0 auto; padding-top: 50px;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grid search\n",
    "\n",
    "* Easy to implement (many apis E.g.: scikit)\n",
    "* Works fine with few hyperparameters (low dimensionality)\n",
    "* the number of experiments grows exponentially\n",
    "<br><br><br>\n",
    "<div>\n",
    "    <img src=\"img/grid.png\" style=\"width:400px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Random search\n",
    "\n",
    "* Easy to implement (many apis E.g.: scikit)\n",
    "* Works fine with few hyperparameters (low dimensionality)\n",
    "* the number of experiments grows exponentially\n",
    "<br><br><br>\n",
    "<div>\n",
    "    <img src=\"img/random.png\" style=\"width:400px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grid search x random search\n",
    "\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/gridxrand.png\" style=\"margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Other optimization techniques\n",
    "\n",
    "* **Bayesian Optimization**\n",
    "  * A black-box estimator to approximate complex functions\n",
    "* Successive Halving\n",
    "  * hyper parameter configuration set is definied randomly\n",
    "  * throw out the worst performing trials and only continue running the best performing trials, until a single hyper parameter configuration remains.\n",
    "* Hyperband\n",
    "  * a grid search over the optimal allocation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optuna: Optimization Framework\n",
    "    \n",
    "### Paper:\n",
    "[**Optuna: A Next-generation Hyperparameter Optimization Framework. In KDD.**](https://arxiv.org/abs/1907.10902)\n",
    "\n",
    "Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta,and Masanori Koyama. 2019.\n",
    "\n",
    "KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Overview of Optunaâ€™s system design\n",
    "<img src=\"img/optuna_flow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optuna Key features\n",
    "\n",
    "* Eager search spaces using bayesian methods with pruning system\n",
    "* Efficiently search large spaces (Using prune unpromising trials for faster results)\n",
    "  * Asynchronous Successive Halving (ASHA)\n",
    "    * combine random search with principled early stopping in an asynchronous way\n",
    "* Easy to parallelize hyperparameter searches over multiple threads/processes\n",
    "  * We just need to run the python script passing the DB path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to install?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "!pip install optuna\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Default pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Create a wrapper of your main algorithm to be optimized that receives an optuna object called `trial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "def objective(trial):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Inside your `objective` function, use `optuna` methods to define your hiperparameters range:\n",
    "   * `optuna.trial.Trial.suggest_categorical()` for categorical parameters\n",
    "   * `optuna.trial.Trial.suggest_int()` for integer parameters\n",
    "   * `optuna.trial.Trial.suggest_float()` for floating point parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "E.g.:\n",
    "```\n",
    "# Categorical parameter\n",
    "optimizer = trial.suggest_categorical(\"optimizer\", [\"MomentumSGD\", \"Adam\"])\n",
    "\n",
    "# Integer parameter\n",
    "num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "\n",
    "# Integer parameter (log)\n",
    "num_channels = trial.suggest_int(\"num_channels\", 32, 512, log=True)\n",
    "\n",
    "# Integer parameter (discretized)\n",
    "num_units = trial.suggest_int(\"num_units\", 10, 100, step=5)\n",
    "\n",
    "# Floating point parameter\n",
    "dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 1.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The `objective` function needs to return an evaluation parameter to be `maximized` or `minimized`\n",
    "   * E.g.:\n",
    "      * `maximization` of accuracy\n",
    "      * `minimization` of EMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* To provide data for `pruning` function works, we need to send an intermediate evaluation parameter value to `optuna` object\n",
    "\n",
    "```\n",
    "...\n",
    "trial.report(accuracy, epoch)\n",
    "\n",
    "if trial.should_prune():\n",
    "    raise optuna.exceptions.TrialPruned()\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Create a `study` object to call the `object` function:\n",
    "   * set the study name (the name of database table)\n",
    "   * set a database to store the experiment data\n",
    "   * set `load_if_exists=True` if you want to use a database that you already created \n",
    "   * set the optimization direction (`maximize` or `minimize`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-22 10:49:43,518]\u001b[0m Using an existing study with name 'opt_tutorial2' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name='opt_tutorial2',\n",
    "    storage='sqlite:///tutorial.db',\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Run the optimization loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "study.optimize(objective, n_trials=50,timeout=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* To check the values after (or while) optimization loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "    Value:  0.8296875\n",
      "Params: \n",
      "    dropout_l0: 0.2083603371473296\n",
      "    dropout_l1: 0.29475991600696116\n",
      "    lr: 0.004143220502481869\n",
      "    n_layers: 2\n",
      "    n_units_l0: 119\n",
      "    n_units_l1: 89\n",
      "    optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(\"    Value: \", trial.value)\n",
    "\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ok, but...\n",
    "<br>\n",
    "<div>\n",
    "    <img src=\"img/talk-is-cheap-show-me-the-code.jpg\" style=\"width:500px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This tutorial will use the following notebooks to explain the implementation of the optimization study:\n",
    "\n",
    "* `opt_tutorial_1.ipynb` (running model without optuna)\n",
    "* `opt_tutorial_2.ipynb` (running the optimization study with optuna)\n",
    "* `opt_tutorial_3.ipynb` (Data visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>After this tutorial...</h1></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "    <img src=\"img/peter.gif\" style=\"width:900px; margin:0 auto;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tks!\n",
    "\n",
    "**e-mail:** \n",
    "* jefferson.jesus@itau-unibanco.com.br\n",
    "* jefferson@fialhocoelho.com.br\n",
    "\n",
    "\n",
    "**tutorial repo:** [github.com/fialhocoelho/optune-tutorial](https://github.com/fialhocoelho/optune-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Useful links:\n",
    "\n",
    "* [Why Is Random Search Better Than Grid Search For Machine Learning](https://analyticsindiamag.com/why-is-random-search-better-than-grid-search-for-machine-learning)\n",
    "* [Hyper Parameter Tuning â€” A Tutorial](https://towardsdatascience.com/hyper-parameter-tuning-a-tutorial-70dc6c552c54)\n",
    "* [Hyperparameter Optimization With Random Search and Grid Search](https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "[Python3] Jeff ML Default",
   "language": "python",
   "name": "ml_default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
